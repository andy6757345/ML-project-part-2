# accuracy 0.69447
# Svm model
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE, ADASYN
from imblearn.under_sampling import TomekLinks
from sklearn.utils.class_weight import compute_class_weight

# Load training dataset
train_df = pd.read_csv('train.csv')

# Drop irrelevant columns and handle missing values
train_df.drop(columns=['trip_ID', 'special_requirements'], inplace=True)
train_df.dropna(subset=['category'], inplace=True)

# Impute missing values for 'female_count' and 'male_count'
train_df['female_count'] = train_df['female_count'].fillna(train_df['female_count'].median())
train_df['male_count'] = train_df['male_count'].fillna(train_df['male_count'].median())

# Feature Engineering: create additional useful features
train_df['total_people'] = train_df['female_count'] + train_df['male_count']
train_df['female_to_male_ratio'] = train_df['female_count'] / (train_df['male_count'] + 1)

# Categorical processing with one-hot encoding
categorical_cols = train_df.select_dtypes(include=['object']).columns
train_df[categorical_cols] = train_df[categorical_cols].fillna('Unknown')
train_df = pd.get_dummies(train_df, columns=categorical_cols, drop_first=True)

# Prepare features (X) and target (y)
X = train_df.drop(columns=['category'])
y = train_df['category']

# Standardize numerical features
numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns
scaler = StandardScaler()
X[numerical_cols] = scaler.fit_transform(X[numerical_cols])

# Handle class imbalance with SMOTE (you can also try ADASYN or Tomek Links)
smote = SMOTE(random_state=42)  # You can switch to ADASYN here
X_res, y_res = smote.fit_resample(X, y)

# Optional: Use Tomek Links to clean the data (remove noise)
tomek = TomekLinks()
X_res, y_res = tomek.fit_resample(X_res, y_res)

# Split the dataset into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_res, y_res, test_size=0.2, random_state=42)

# Compute class weights for SVM (important if the classes are still imbalanced)
class_weights = compute_class_weight('balanced', classes=np.unique(y_res), y=y_res)
class_weight_dict = dict(zip(np.unique(y_res), class_weights))

# Initialize the SVM model with RBF kernel
svm = SVC(probability=True, random_state=42, class_weight=class_weight_dict, kernel='rbf')

# SVM Hyperparameter Grid (2 candidates for each parameter)
svm_param_grid = {
    'C': [1, 10],  # 2 candidates for C
    'gamma': [0.1, 0.01]  # 2 candidates for gamma
}

# RandomizedSearchCV with 4 folds, 2 candidates, and 2 fits
svm_random_search = RandomizedSearchCV(
    estimator=svm,
    param_distributions=svm_param_grid,
    cv=4,  # 4-fold cross-validation
    scoring='accuracy',
    n_jobs=-1,
    verbose=2,
    n_iter=2,  # 2 fits (iterations of hyperparameter search)
    random_state=42
)

# Fit the model using RandomizedSearchCV
svm_random_search.fit(X_train, y_train)

# Evaluate the best model from RandomizedSearchCV
best_svm = svm_random_search.best_estimator_
y_pred_svm = best_svm.predict(X_val)
val_accuracy_svm = accuracy_score(y_val, y_pred_svm)
print(f"SVM Validation Accuracy: {val_accuracy_svm}")
print("SVM Classification Report:\n", classification_report(y_val, y_pred_svm))

# Prepare the test data and make predictions
test_df = pd.read_csv('test.csv')
test_df.drop(columns=['trip_ID', 'special_requirements'], inplace=True)
test_df['female_count'] = test_df['female_count'].fillna(test_df['female_count'].median())
test_df['male_count'] = test_df['male_count'].fillna(test_df['male_count'].median())

# Feature Engineering for test data
test_df['total_people'] = test_df['female_count'] + test_df['male_count']
test_df['female_to_male_ratio'] = test_df['female_count'] / (test_df['male_count'] + 1)

# Categorical processing with one-hot encoding for test data
test_df[categorical_cols] = test_df[categorical_cols].fillna('Unknown')
test_df = pd.get_dummies(test_df, columns=categorical_cols, drop_first=True)

# Ensure the test set columns match the training set
test_df = test_df.reindex(columns=X.columns, fill_value=0)
test_df[numerical_cols] = scaler.transform(test_df[numerical_cols])

# Predictions on test data using the best SVM model
pred_probs = best_svm.predict_proba(test_df)
results = pd.DataFrame({
    'trip_ID': pd.read_csv('test.csv')['trip_ID'],
    'category': np.argmax(pred_probs, axis=1)
})

# Save predictions
results.to_csv('predictions_optimized_svm2.csv', index=False)
